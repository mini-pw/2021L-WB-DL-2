{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WB PD4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR39BvkMmVIU"
      },
      "source": [
        "# Zjawisko niepewności w sieciach neuronowych\n",
        "Dotyczy wpływu małych perturbacji na działanie i skuteczne przewidywania naszego modelu. W artykule https://arxiv.org/abs/1901.07152 przedstawione są 3 sposoby wprowadzania takowych zniekształceń. Należą do nich zmiany trenowalnych parametrów jednej lub wszystkich warstw oraz 'zaszumienie' danych wejściowych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmre3Gv97wQ"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.metrics import TruePositives\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCAiAxVla1VQ"
      },
      "source": [
        "# Dane i model\n",
        "Dane którymi będę się posługiwać jest dobrze znany i lubiany zbiór CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6sUfncA_Hpk"
      },
      "source": [
        "(X_train,y_train), (X_test,y_test) = cifar10.load_data()\n",
        "\n",
        "y_train = y_train.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "X_test = X_test /255\n",
        "X_train = X_train /255"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTwRfNWtaZLp"
      },
      "source": [
        "Źródło modelu: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3eP5gxVCMCm",
        "outputId": "c721db18-1418-425b-f250-9f4d43013a01"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFDlbBtoC756",
        "outputId": "e46117e9-e63c-4015-bfd9-2b5bc0e5f444"
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs = 10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 11s 6ms/step - loss: 1.9549 - accuracy: 0.3635\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1180 - accuracy: 0.6081\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9225 - accuracy: 0.6805\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8140 - accuracy: 0.7192\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7316 - accuracy: 0.7491\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6736 - accuracy: 0.7704\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6299 - accuracy: 0.7840\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5859 - accuracy: 0.7997\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5525 - accuracy: 0.8111\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5168 - accuracy: 0.8217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70d23f0410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syrp7fkIoATU"
      },
      "source": [
        "Tutaj sprawdzamy jak nasz model sobie radzi przed wprowadzeniem jakichkolwiek zmian oraz zapisujemy wszystie wytrenowane parametry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "H8vQeMqVDr6b",
        "outputId": "083ea2e1-996f-4538-9a0a-dcdb5491f22c"
      },
      "source": [
        "layers_weights=[]\n",
        "for layer in model.layers:\n",
        "  layers_weights.append(layer.get_weights())\n",
        "row=model.evaluate(X_test,y_test)\n",
        "data=pd.DataFrame(data=[row],columns=[\"Loss\",\"Accuracy\"])\n",
        "data"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5160 - accuracy: 0.8260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.516018</td>\n",
              "      <td>0.826</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Loss  Accuracy\n",
              "0  0.516018     0.826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XWDnP73agnp"
      },
      "source": [
        "Funkcja do wczytania oryginalnych wag modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFBkhPYDSCA5"
      },
      "source": [
        "def original_model(layers_weights):\n",
        "  for j in range(0,23):\n",
        "    if j in [4,5,10,11,16,17,18,21]: #warstwy bez parametrów\n",
        "      continue\n",
        "    elif j in [1,3,7,9,13,15,20]: #batch normalization\n",
        "      model.layers[j].set_weights([layers_weights[j][0],\n",
        "                                   layers_weights[j][1],\n",
        "                                   layers_weights[j][2],\n",
        "                                   layers_weights[j][3]])\n",
        "    else:                         #conv2D i dense\n",
        "      model.layers[j].set_weights([layers_weights[j][0],\n",
        "                                   layers_weights[j][1]])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9WbtMSaq8L"
      },
      "source": [
        "# Zmiana wag jednej warstwy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMk_xLQEb2Pv"
      },
      "source": [
        "Pierwszy test bedzie dotyczył zmian w wagach i biasach warstwy Dense. Każda z nich zostanie losowo pomnożona przez liczbę z zakresu [0.1,10]. Eksperyment zostanie powtórzony 50 razy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-ZuBBrGJuzh",
        "outputId": "ba287350-b423-45ef-de5d-b3a487817ca3"
      },
      "source": [
        "original_model(layers_weights)\n",
        "rows=[]\n",
        "for i in range(1,51):\n",
        "  model.layers[19].set_weights([layers_weights[19][0]*np.random.uniform(low=0.1,high=10,size=(2048,128)),\n",
        "                                layers_weights[19][1]*np.random.uniform(low=0.1,high=10,size=128)])\n",
        "  print(i)\n",
        "  row=model.evaluate(X_test,y_test)\n",
        "  rows.append(row)\n",
        "data=pd.DataFrame(data=rows,columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9828 - accuracy: 0.7948\n",
            "2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9961 - accuracy: 0.7952\n",
            "3\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9434 - accuracy: 0.7974\n",
            "4\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9913 - accuracy: 0.7959\n",
            "5\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9586 - accuracy: 0.7982\n",
            "6\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9397 - accuracy: 0.7984\n",
            "7\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9821 - accuracy: 0.7958\n",
            "8\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0035 - accuracy: 0.7939\n",
            "9\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0055 - accuracy: 0.7969\n",
            "10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9457 - accuracy: 0.7963\n",
            "11\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0182 - accuracy: 0.7934\n",
            "12\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0364 - accuracy: 0.7947\n",
            "13\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9722 - accuracy: 0.7959\n",
            "14\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9837 - accuracy: 0.7936\n",
            "15\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9812 - accuracy: 0.7964\n",
            "16\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9832 - accuracy: 0.7953\n",
            "17\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9770 - accuracy: 0.7956\n",
            "18\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0322 - accuracy: 0.7917\n",
            "19\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0238 - accuracy: 0.7947\n",
            "20\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9635 - accuracy: 0.7954\n",
            "21\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9493 - accuracy: 0.7968\n",
            "22\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9575 - accuracy: 0.7967\n",
            "23\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9987 - accuracy: 0.7933\n",
            "24\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9772 - accuracy: 0.7960\n",
            "25\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9930 - accuracy: 0.7959\n",
            "26\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9895 - accuracy: 0.7940\n",
            "27\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9540 - accuracy: 0.7969\n",
            "28\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9930 - accuracy: 0.7940\n",
            "29\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9492 - accuracy: 0.7977\n",
            "30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9708 - accuracy: 0.7961\n",
            "31\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9930 - accuracy: 0.7947\n",
            "32\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0480 - accuracy: 0.7926\n",
            "33\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9903 - accuracy: 0.7949\n",
            "34\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9669 - accuracy: 0.7972\n",
            "35\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9855 - accuracy: 0.7938\n",
            "36\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9728 - accuracy: 0.7964\n",
            "37\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9420 - accuracy: 0.7997\n",
            "38\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0071 - accuracy: 0.7925\n",
            "39\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9763 - accuracy: 0.7971\n",
            "40\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9991 - accuracy: 0.7940\n",
            "41\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9732 - accuracy: 0.7965\n",
            "42\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9466 - accuracy: 0.7956\n",
            "43\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9852 - accuracy: 0.7961\n",
            "44\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0036 - accuracy: 0.7948\n",
            "45\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9719 - accuracy: 0.7972\n",
            "46\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9826 - accuracy: 0.7963\n",
            "47\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.0033 - accuracy: 0.7927\n",
            "48\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9878 - accuracy: 0.7955\n",
            "49\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9884 - accuracy: 0.7964\n",
            "50\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9442 - accuracy: 0.7973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "vV89kJ64P40y",
        "outputId": "f4e48f40-5d5a-4701-e339-d53ec62837a6"
      },
      "source": [
        "a=data.std(axis=0).to_numpy()\n",
        "b=data.mean(axis=0).to_numpy()\n",
        "pd.DataFrame([a,b],index=[\"Std\",\"Mean\"],columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Std</th>\n",
              "      <td>0.025147</td>\n",
              "      <td>0.001658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>1.982403</td>\n",
              "      <td>0.795564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Loss  Accuracy\n",
              "Std   0.025147  0.001658\n",
              "Mean  1.982403  0.795564"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAQv2-h9cci6"
      },
      "source": [
        "Mimo możliwych dużych różnic w wagach i biasach accuracy tylko trochę się pogorszyło."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIBcPM0zc_Nu"
      },
      "source": [
        "Sprawdźmy teraz czy otrzymamy podobny wynik zmieniając w ten sam sposób parametry warstwy konwolucyjnej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPKNI9o4TzzL",
        "outputId": "c3447631-9085-4846-aa4a-2e9771845077"
      },
      "source": [
        "original_model(layers_weights)\n",
        "rows=[]\n",
        "low=0.1\n",
        "high=10\n",
        "for i in range(1,51):\n",
        "  size1=layers_weights[2][0].shape\n",
        "  size2=layers_weights[2][1].shape\n",
        "  model.layers[2].set_weights([layers_weights[2][0]*np.random.uniform(low=low,high=high,size=size1),\n",
        "                               layers_weights[2][1]*np.random.uniform(low=low,high=high,size=size2)])\n",
        "  print(i)\n",
        "  row=model.evaluate(X_test,y_test)\n",
        "  rows.append(row)\n",
        "data=pd.DataFrame(data=rows,columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4623 - accuracy: 0.4864\n",
            "2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3922 - accuracy: 0.5356\n",
            "3\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2830 - accuracy: 0.5252\n",
            "4\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2892 - accuracy: 0.5198\n",
            "5\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6273 - accuracy: 0.5013\n",
            "6\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3530 - accuracy: 0.5235\n",
            "7\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.7184 - accuracy: 0.4171\n",
            "8\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3994 - accuracy: 0.4919\n",
            "9\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6893 - accuracy: 0.4778\n",
            "10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4973 - accuracy: 0.5072\n",
            "11\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6419 - accuracy: 0.4885\n",
            "12\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.0326 - accuracy: 0.4523\n",
            "13\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4827 - accuracy: 0.5085\n",
            "14\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.7463 - accuracy: 0.4965\n",
            "15\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2767 - accuracy: 0.5228\n",
            "16\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.3646 - accuracy: 0.4446\n",
            "17\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6066 - accuracy: 0.5108\n",
            "18\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.8844 - accuracy: 0.4704\n",
            "19\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3646 - accuracy: 0.5189\n",
            "20\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3793 - accuracy: 0.5029\n",
            "21\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.5978 - accuracy: 0.4888\n",
            "22\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.7978 - accuracy: 0.4701\n",
            "23\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9302 - accuracy: 0.5499\n",
            "24\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4089 - accuracy: 0.5001\n",
            "25\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.5081 - accuracy: 0.4227\n",
            "26\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.1136 - accuracy: 0.4461\n",
            "27\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4319 - accuracy: 0.5230\n",
            "28\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3616 - accuracy: 0.5107\n",
            "29\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4335 - accuracy: 0.4955\n",
            "30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.7798 - accuracy: 0.4655\n",
            "31\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2445 - accuracy: 0.5322\n",
            "32\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6296 - accuracy: 0.5085\n",
            "33\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4218 - accuracy: 0.5091\n",
            "34\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3738 - accuracy: 0.5228\n",
            "35\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6643 - accuracy: 0.4896\n",
            "36\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.0892 - accuracy: 0.4490\n",
            "37\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.5956 - accuracy: 0.4790\n",
            "38\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.0234 - accuracy: 0.4559\n",
            "39\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6455 - accuracy: 0.5003\n",
            "40\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4239 - accuracy: 0.4998\n",
            "41\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.7178 - accuracy: 0.4901\n",
            "42\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.7564 - accuracy: 0.4713\n",
            "43\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.2003 - accuracy: 0.4526\n",
            "44\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2228 - accuracy: 0.5236\n",
            "45\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.7206 - accuracy: 0.5006\n",
            "46\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3186 - accuracy: 0.5204\n",
            "47\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.6681 - accuracy: 0.4893\n",
            "48\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4103 - accuracy: 0.5134\n",
            "49\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.2420 - accuracy: 0.5338\n",
            "50\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 3.2251 - accuracy: 0.4548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EC43G0VT1hG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "1f3a2c0f-180f-4812-9a5e-49e821ec0bb8"
      },
      "source": [
        "a=data.std(axis=0).to_numpy()\n",
        "b=data.mean(axis=0).to_numpy()\n",
        "pd.DataFrame([a,b],index=[\"Std\",\"Mean\"],columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Std</th>\n",
              "      <td>0.358715</td>\n",
              "      <td>0.030121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>2.628953</td>\n",
              "      <td>0.493410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Loss  Accuracy\n",
              "Std   0.358715  0.030121\n",
              "Mean  2.628953  0.493410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft1SWPG2dMT4"
      },
      "source": [
        "Średnie accuracy pogorszyło się tym razem znacząco. Również odchylenie standardowe wzrosło w porównaniu do poprzedniego przykładu. Różnica może wynikać z umiejscowienia tych warstw w sieci. Mam przez to na myśli, że znaczenie błędów powstałych w warstwie konwolucyjnej na początku urosło wraz z każdą kolejną warstwą powodując duże różnice na wyjściu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j43rdqzKeHxP"
      },
      "source": [
        "# Zmiana wag wszystkich warstwy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFbZJmwKeNd2"
      },
      "source": [
        "Tym razem będziemy mnożyć wszystkie trenowalne parametry przez liczby losowane z zakresu [0.7,1.2]. Zakres został znacznie zmniejszony ponieważ ilość parametrów, na które wpływamy tym razem jest dużo większa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4SUTUjMEFvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c914bdb-2fba-4a0a-e087-b87f604cc32a"
      },
      "source": [
        "original_model(layers_weights)\n",
        "rows=[]\n",
        "low=0.7\n",
        "high=1.2\n",
        "for i in range(1,51):\n",
        "  original_model(layers_weights)\n",
        "  for j in range(0,23):\n",
        "    if j in [4,5,10,11,16,17,18,21]: #warstwy bez parametrów\n",
        "      continue\n",
        "\n",
        "    elif j in [1,3,7,9,13,15,20]: #batch normalization\n",
        "      size1=layers_weights[j][0].shape\n",
        "      size2=layers_weights[j][1].shape\n",
        "      size3=layers_weights[j][2].shape\n",
        "      size4=layers_weights[j][3].shape\n",
        "      model.layers[j].set_weights([layers_weights[j][0]*np.random.uniform(low=low,high=high,size=size1),\n",
        "                                   layers_weights[j][1]*np.random.uniform(low=low,high=high,size=size2),\n",
        "                                   layers_weights[j][2]*np.random.uniform(low=low,high=high,size=size3),\n",
        "                                   layers_weights[j][3]*np.random.uniform(low=low,high=high,size=size4)])\n",
        "      \n",
        "    else:                         #conv2D i dense\n",
        "      size1=layers_weights[j][0].shape\n",
        "      size2=layers_weights[j][1].shape\n",
        "      model.layers[j].set_weights([layers_weights[j][0]*np.random.uniform(low=low,high=high,size=size1),\n",
        "                                   layers_weights[j][1]*np.random.uniform(low=low,high=high,size=size2)])\n",
        "  print(i)\n",
        "  row=model.evaluate(X_test,y_test)\n",
        "  rows.append(row)\n",
        "data=pd.DataFrame(data=rows,columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0117 - accuracy: 0.6517\n",
            "2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7819 - accuracy: 0.7313\n",
            "3\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0617 - accuracy: 0.6365\n",
            "4\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4278 - accuracy: 0.5183\n",
            "5\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9721 - accuracy: 0.6672\n",
            "6\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.9674 - accuracy: 0.4092\n",
            "7\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1241 - accuracy: 0.6216\n",
            "8\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7508 - accuracy: 0.7512\n",
            "9\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0746 - accuracy: 0.6338\n",
            "10\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3939 - accuracy: 0.5766\n",
            "11\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.4086 - accuracy: 0.3562\n",
            "12\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8712 - accuracy: 0.7060\n",
            "13\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9364 - accuracy: 0.6665\n",
            "14\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1136 - accuracy: 0.6307\n",
            "15\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5982 - accuracy: 0.4595\n",
            "16\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2138 - accuracy: 0.5973\n",
            "17\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9821 - accuracy: 0.6680\n",
            "18\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8176 - accuracy: 0.7331\n",
            "19\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8780 - accuracy: 0.6894\n",
            "20\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2677 - accuracy: 0.5742\n",
            "21\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5826 - accuracy: 0.4653\n",
            "22\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6876 - accuracy: 0.7730\n",
            "23\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7097 - accuracy: 0.7630\n",
            "24\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4401 - accuracy: 0.5092\n",
            "25\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1265 - accuracy: 0.6366\n",
            "26\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0808 - accuracy: 0.6465\n",
            "27\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9857 - accuracy: 0.6664\n",
            "28\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8212 - accuracy: 0.7317\n",
            "29\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2352 - accuracy: 0.5652\n",
            "30\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8474 - accuracy: 0.7044\n",
            "31\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0613 - accuracy: 0.6305\n",
            "32\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7905 - accuracy: 0.7362\n",
            "33\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.8658 - accuracy: 0.4234\n",
            "34\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9408 - accuracy: 0.6737\n",
            "35\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9525 - accuracy: 0.6787\n",
            "36\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7982 - accuracy: 0.7209\n",
            "37\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7480 - accuracy: 0.4338\n",
            "38\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7446 - accuracy: 0.7484\n",
            "39\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.6248 - accuracy: 0.4741\n",
            "40\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8960 - accuracy: 0.6928\n",
            "41\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0564 - accuracy: 0.6260\n",
            "42\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7881 - accuracy: 0.7315\n",
            "43\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2817 - accuracy: 0.5911\n",
            "44\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9797 - accuracy: 0.6639\n",
            "45\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4750 - accuracy: 0.4737\n",
            "46\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0879 - accuracy: 0.6275\n",
            "47\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7321 - accuracy: 0.4789\n",
            "48\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9777 - accuracy: 0.6623\n",
            "49\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0846 - accuracy: 0.6325\n",
            "50\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1476 - accuracy: 0.6089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQOk77JU2DWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "8a08e17d-6a0e-4d50-f487-60b401d4c49c"
      },
      "source": [
        "a=data.std(axis=0).to_numpy()\n",
        "b=data.mean(axis=0).to_numpy()\n",
        "pd.DataFrame([a,b],index=[\"Std\",\"Mean\"],columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Std</th>\n",
              "      <td>0.365832</td>\n",
              "      <td>0.103849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>1.144072</td>\n",
              "      <td>0.620968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Loss  Accuracy\n",
              "Std   0.365832  0.103849\n",
              "Mean  1.144072  0.620968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMk9-H0de3Ow"
      },
      "source": [
        "W tym przypadku również widzimy spory spadek accuracy oraz większe niż w poprzednich przypadkach odchylenie standardowe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWT9YS4PfF13"
      },
      "source": [
        "# Perturbacja danych wejściowych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fZCk3g6iaZj"
      },
      "source": [
        "Każdy piksel zostanie pomnożony przez losową liczbę z zakresu [0.7,1.2]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSVo_wftELc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3d19c1-6141-4f2e-8c45-6066fe2053f5"
      },
      "source": [
        "rows=[]\n",
        "original_model(layers_weights)\n",
        "for i in range(1,50):\n",
        "  original_model(layers_weights)\n",
        "  test_images = [img*np.random.uniform(low=0.7,high=1.2,size=(10000, 32, 32, 3)) for img in [X_test]]\n",
        "  row=[i/10]+model.evaluate(test_images,y_test)\n",
        "  rows.append(row)\n",
        "data=pd.DataFrame(data=rows,columns=['i','Loss','Accuracy'])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1351 - accuracy: 0.4203\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1445 - accuracy: 0.4176\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1472 - accuracy: 0.4193\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1387 - accuracy: 0.4156\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1488 - accuracy: 0.4145\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1418 - accuracy: 0.4159\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1395 - accuracy: 0.4208\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1432 - accuracy: 0.4198\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1482 - accuracy: 0.4175\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1431 - accuracy: 0.4203\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1554 - accuracy: 0.4175\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1426 - accuracy: 0.4171\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1415 - accuracy: 0.4166\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1548 - accuracy: 0.4143\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1375 - accuracy: 0.4190\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1453 - accuracy: 0.4156\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1442 - accuracy: 0.4221\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1460 - accuracy: 0.4184\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1407 - accuracy: 0.4177\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1470 - accuracy: 0.4193\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1414 - accuracy: 0.4140\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1382 - accuracy: 0.4189\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1397 - accuracy: 0.4199\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1397 - accuracy: 0.4182\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1340 - accuracy: 0.4228\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1458 - accuracy: 0.4153\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1410 - accuracy: 0.4208\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1510 - accuracy: 0.4184\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1466 - accuracy: 0.4169\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1434 - accuracy: 0.4186\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1511 - accuracy: 0.4156\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1521 - accuracy: 0.4154\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1468 - accuracy: 0.4186\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1420 - accuracy: 0.4216\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1447 - accuracy: 0.4202\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1423 - accuracy: 0.4185\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1471 - accuracy: 0.4187\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1446 - accuracy: 0.4169\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1364 - accuracy: 0.4163\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1435 - accuracy: 0.4182\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1446 - accuracy: 0.4194\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1457 - accuracy: 0.4169\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1380 - accuracy: 0.4186\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1458 - accuracy: 0.4194\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1496 - accuracy: 0.4157\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1363 - accuracy: 0.4170\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1434 - accuracy: 0.4187\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1432 - accuracy: 0.4188\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1378 - accuracy: 0.4183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4SeXzbwjybz"
      },
      "source": [
        "Porównanie obrazków."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "gkVL-ybViKl_",
        "outputId": "6d47369e-8a8b-4d2a-eca0-a58caec15ea7"
      },
      "source": [
        "plt.imshow(test_images[0][0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f70fe0c3490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "8gfHmPvMiL6H",
        "outputId": "0a4fb73c-c0bc-4213-e10f-42ef6cf6cf38"
      },
      "source": [
        "plt.imshow(X_test[0])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f70d3ddcbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDW4EkmkR6nP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "bea55a07-ab7a-4f89-8e28-474a73dd7a2a"
      },
      "source": [
        "a=data.std(axis=0).to_numpy()[1:]\n",
        "b=data.mean(axis=0).to_numpy()[1:]\n",
        "pd.DataFrame([a,b],index=[\"Std\",\"Mean\"],columns=[\"Loss\",\"Accuracy\"])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Std</th>\n",
              "      <td>0.004829</td>\n",
              "      <td>0.002026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>2.143682</td>\n",
              "      <td>0.418078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Loss  Accuracy\n",
              "Std   0.004829  0.002026\n",
              "Mean  2.143682  0.418078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3uodNoZkjJZ"
      },
      "source": [
        "Wprowadzone perturbacje wyraźnie pogorszyły trafność modelu ale ciekawe jest to, że tym razem odchylenie standardowe nie jest zauważalnie duże."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJjAjgd1pEtE"
      },
      "source": [
        "# Podsumowanie\n",
        "Największą różnicę w wynikach uzyskałem wprowadzjąc szum do danych wejściowych. Jeśli model nie uczył się na zaszumionych danych to ma to jak najbardziej sens. Również perturbację w początkowych warstwach bardzo negatywnie odbijają się na całym modelu, ponieważ tak jak wspomniałem wcześniej znaczenie tego błędu może nabierać na sile przy przechodzeniu przez kolejne warstwy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoG7qIipoTM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}