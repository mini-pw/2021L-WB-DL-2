{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PD3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZB0JjNhP4p5"
      },
      "source": [
        "# Praca domowa 3 - Ablation study \n",
        "Tematem tej pracy domowej jest zapoznanie się z Ablation study oraz zbadanie wpływu różnych modyfikacje na przykładową sieć.\n",
        "\n",
        "## Ablation study\n",
        " W kontekcie uczenia maszynowego ablation study oznacza modyfikowanie modelu uczącego w celu zbadania wpływu poszczegulnych jego elementów, lub parametrów uczenia na wynik oraz prędkość uczenia. Ablation study pozwala zatem zbadać, które elementy modelu są kluczowe, a które tylko spowalniają uczenie. Umożliwia to lepsze zrozumienie modelu i ewentualne usprawnienie jego działania i być może poprawienia wyniku uczenia.\n",
        "\n",
        " source: \"https://stats.stackexchange.com/questions/380040/what-is-an-ablation-study-and-is-there-a-systematic-way-to-perform-it\" \\\\\n",
        " \"https://arxiv.org/abs/1901.08644\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebKd4qVevfvv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Activation\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4Xra8kQkI-"
      },
      "source": [
        "W celu przeprowadzenia modyfikacji posłużę się modelem, którego celem będzie rozpoznawanie cyfr ze zbioru MNIST. Do wczytania i przetworzenia danych w celu użycia ich potem w modelu wspomogłem się kodem zamieszczonym na stronie kerasa: \"https://keras.io/examples/vision/mnist_convnet/\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itMXxXmWwKwP",
        "outputId": "7a3dad2d-67dc-487f-87d3-4e97dfefa393"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 20\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWF3k7nFqlp",
        "outputId": "2de09167-9ead-494d-bb50-c0c6e8db8410"
      },
      "source": [
        "def base_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(32,(3,3),padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_n = base_model()\n",
        "cnn_n.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 865,322\n",
            "Trainable params: 865,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8XBsSP1ObGv"
      },
      "source": [
        "# Sprawdzenie wyników dla początkowej sieci\n",
        "\n",
        "Na początku trenujemy naszą podstawową sieć, aby sprawdzić jakie wyniki będzie osiągać "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGlSeoOWFtg8",
        "outputId": "784581de-ee26-4e67-eda4-4e88c4750c76"
      },
      "source": [
        "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True, verbose=0)\n",
        "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.024178624153137207\n",
            "Test accuracy: 0.9929999709129333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnTMkyGpQ5Ky"
      },
      "source": [
        "Sieć uzyskała zadowalające wyniki. Sprawdzimy teraz jak poradzą sobie zmodyfikowane sieci i czy zmiany te będą miały wpływ na wyniki lub szybkość."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeGqmvAYQ3d1"
      },
      "source": [
        "# Sprawdzenie wyników dla sieci bez gęstej warstwy\n",
        "\n",
        "Sprawdzimy czy usunięcie warstwy dense zmieni wyniki sieci."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqu59pcURWvL",
        "outputId": "e6cfee9b-5b31-4716-8cd8-0b6ce18f7d71"
      },
      "source": [
        "def without_dense_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(32,(3,3),padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_n = without_dense_model()\n",
        "\n",
        "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True, verbose=0)\n",
        "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.0225150715559721\n",
            "Test accuracy: 0.9925000071525574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEqCUmj9WYeW"
      },
      "source": [
        "Usunięcie warstwy dense nie wpłynęło w tym przypadku na wynik sieci. Wspomogło to za to delikatnie wydajność, gdyż zmalała ilość parametrów do wytrenowania."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeQWClpvSUD6"
      },
      "source": [
        "# Sprawdzenie wyników dla sieci bez warstwy konwolucyjnej\n",
        "\n",
        "Sprawdzimy czy usunięcie warstwy konwolucyjnej zmieni wyniki sieci."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TOvSugcSYmv",
        "outputId": "12b76de0-02ba-41bd-d37f-406999adac39"
      },
      "source": [
        "def without_conv_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_n = without_conv_model()\n",
        "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True, verbose=0)\n",
        "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.030443163588643074\n",
            "Test accuracy: 0.9901999831199646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73AYUKYMTKFx"
      },
      "source": [
        "W porównaniu z usunięciem warstwy dense otrzymaliśmy znacznie więcej parametrów. Jeśli chodzi o wynik to spadł on bardziej niż w przypadku usunięcia warstwy gęstej. Można wnoskować zatem, że wartwy konwolucyjne mają w tym przypadku większy wpływ na wynik sieci.\n",
        "\n",
        "## Zmniejszenie neuronów w pierwszej warstwie dense\n",
        "Najbardziej 'zasobożerną' częścią modelu jest warstwa dens po operacji wypłaszczenia. Sprawdzimy czy zmniejszenie ilości neuronów w tej sieci wpłynie na wynik. Jeżeli wynik się nie zmieni to może okazać się, że możemy zoptymalizować nasz model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsYw18PXgCV",
        "outputId": "b0bda861-3bea-4c52-cd72-e87b8a389636"
      },
      "source": [
        "def less_params_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(16,(3,3),padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(32,activation='relu',kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_n = less_params_model()\n",
        "cnn_n.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                100384    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 106,714\n",
            "Trainable params: 106,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UP-8EXhaaAA"
      },
      "source": [
        "Tym razem nie usuneliśmy żadnej warstwy, natomiast zmodyfikowaliśmy parametry warstw, aby zminimalizować liczbę parametrów do wytrenowania."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ56CFTMXo5R",
        "outputId": "fa2dca7b-9025-4a1f-e3b5-b55f9290a236"
      },
      "source": [
        "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True, verbose=0)\n",
        "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.03733927011489868\n",
            "Test accuracy: 0.988099992275238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqN-VXsWY35t"
      },
      "source": [
        "Zmniejszenie liczby parametrów znacząco wpłyneło na wynik modelu. Trenowanie zostało lekko przyspieszone jednak kosztem końcowego wyniku sieci. Sieci też dużo wolniej osiągnełą wysokie wyniki, więc gdybyśmy wzieli mniej epok wynik mógłby być jeszcze gorszy niż dla początkowego modelu z tą samą ilością epok.\n",
        "\n",
        "## Zmiana batch size \n",
        "Na koniec sprawdzimy czy zmiana batch size wpłynie na wynik modelu. Na początku spróbujemy ustwić duży rozmiar paczki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nipn_R9PbLlm",
        "outputId": "a87a8eff-60c6-4389-aadb-cd8c99984531"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "cnn_n = base_model()\n",
        "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True, verbose=0)\n",
        "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.027661358937621117\n",
            "Test accuracy: 0.9919000267982483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8derfuMN0i",
        "outputId": "08bf48bc-c160-42e6-f244-1b355767ecfd"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "cnn_n = base_model()\n",
        "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True, verbose=0)\n",
        "score = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.021962296217679977\n",
            "Test accuracy: 0.9940000176429749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaYkHLAyqTcL"
      },
      "source": [
        "Batch size w tym przypadku nie robi dużej różnicy, jednak delikatnie lepsze wyniki osiąga zazwyczaj większy batch size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHM4AELfqfav"
      },
      "source": [
        "Powyższe eksperymenty pozwoliły nam sprawdzić, które elementy sieci są dla nas kluczowe, a które być może nawet niepotrzebne. W naszym przypadku większość zmian nie wpłyneła znacząco na wyniki. Tylko znaczące zredukowanie ilości neuronów spowodowało większy spadek dokładności. W pozostałych przypadkach różnice były nieduże. Nasza sieć zapewne była na tyle mocna w porównaniu do stosunkwo prostego zbioru MNIST, że po zmianach dalej świetnie sobie radziła. "
      ]
    }
  ]
}